Homo Cyberneticus: Neurocognitive embodiment of artificial limbs 
Technology is progressing at a remarkable pace, providing us with wearable robotic technologies to substitute, and even supplement, our own limbs, freeing humans from the biological constraints of their own bodies. But can the human brain embody these exciting technologies as new body parts? I will describe very recent neuroimaging and behavioural studies we’ve been conducting in amputees who use prosthetic limbs to substitute their missing hand function. I will then present ongoing studies examining what happens to people’s (intact) biological body representation after they are provided with robotic augmentation – a Third Thumb. We find that although brain resources originally devoted to body representation can be utilised to represent an artificial limb, the representational features of a prosthesis do not mimic that of a biological hand. These studies provide a first glimpse into neurocognitive opportunities and limitations towards artificial limb embodiment. 
Making movement happen: A panel presentation to integrate descending control from the brain to the spinal cord 
Motor control of the body is accomplished through the cooperative actions of the brain, spinal cord, and peripheral nervous system and it is executed through the “final common pathway” of spinal motoneurons. Five pathways convey motor commands and modulatory cues generated within motor centers of the brain to the spinal cord: the cerebellospinal, reticulospinal, vestibulospinal, rubrospinal, and corticospinal tracts. Together, these pathways are critical for all voluntary movement of the body, as underscored by the paralysis that follows severe spinal cord injury. We will present our recent work on the organization and functional roles of selected aspects of these pathways and how this knowledge may be used to bring recovery to injured patients. In the opening talk, Ariel Levine will highlight the cellular diversity in the spinal cord and reveal core principles that link cell types, spatial organization, and function. She will also show how diverse neuronal types are recruited by the cerebellum and the role of this specific descending connectivity in motor behavior. Next, Julien Bouvier will focus on the brainstem reticular formation. He will present novel data that highlight a functional diversity with projection-specialized neuronal subtypes that each control a specific spinal segment. This body oriented functional specialization may underlie the execution of individual motor actions of coherent and multi-faceted behaviors. Third, Vibhu Sanhi will build on this concept of cell-type specialization by axonal target and further exemplify it for the cortico-spinal tract. Importantly, he will touch upon the developmental signals that instruct the formation of such an exquisite connectivity “roadmap” and how these signals might have promising roles for axonal regeneration. Finally, Grégoire Courtine will illustrate how these executive circuits and their supra-spinal commands can be brought back into action in paralyzed animal models and injured patients. He will in particular show how epidural electrical stimulation may amplify residual descending commands and by so enable voluntary movements following spinal cord injury. We will then discuss both a global understanding of how descending motor control systems are structured, as well as the unique features and contributions of each system. We will consider anatomical clues, such as which spinal cord populations and segments are targeted by each descending pathway, as well as functional clues, such as what types of movements and motor features are governed by each descending pathway. Finally, we will build on this knowledge to examine targeted rehabilitative and stimulation strategies for patients suffering from severe spinal cord injury. We hope that this discussion will reveal the gaps and critical next steps in building the molecular, connectomics, and functional “maps” of descending motor control not only in the intact, but also in the diseased and damaged nervous system. 
A novel stochastic optimal control framework to simulate control and move-ment of non-linear systems and its application to standing balance and goal-directed reaching 
Stochastic optimal control (SOC) has been proposed as a theory of motor coordination [1] explaining movement kinematics and variability based on minimizing the effects of physiological noise on the performance of a task-level goal. Due to computational limitations however, SOC has only been applied on simple mechanical models that typically do not account for nonlinear inter-segment interactions and muscle mechanics. Yet, non-linear mechanics can contribute significantly to the required modulation of feedback and feedforward control to stabilize movement against noise. Here, we present method for SOC that allows efficient simulation of nonlinear stochastic systems. Non-Gaussian distributions of the stochastic state trajectory are approximated by Gaussian distributions, allowing the state space to be described by the mean state and state covariance ‘P’. The dynamics of ‘P’ is described by the continuous Lyapunov equation (cfr. propagation rules of the Extended Kalman Filter). The resulting augmented deterministic optimal control problem is solved using direct collocation and gradient-based optimization. We applied this SOC method to muscle-driven (Hill-type muscles) simulations of perturbed standing balance (single- joint) and reaching (two-joint). In both cases we solved for feedforward muscle controls and feedback gains that minimized expected effort (expected muscle excitations squared) while satisfying a specified task goal. Our muscle-driven inverted pendulum model of standing was controlled by proprioceptive and vestibular feedback. In agreement with experiments and SOC simulations with linear torque driven models, we predicted sensory reweighting in favor of vestibular information with increasing platform rotation magnitude and loss of balance for vestibular loss subjects [2]. In addition, our simulations allowed insight in muscle-level motor control strategies. They predicted muscle co-activation as a minimal effort strategy to withstand platform translations - but not rotations - that was larger when accounting for short-range stiffness in the muscle model. Our two-segment muscle-driven arm model of reaching was controlled by time-varying feedback from endpoint kinematics. The simulations predicted experimentally observed reactive muscle activity and kinematic trajectories in response to perturbations depending on target shape [3]. Our simulations of the perturbed kinematic trajectories were in better agreement with experiments than simulations based on point mass models. In conclusion, our novel framework allowed us to demonstrate that SOC predicts task-dependent modulation of feedforward (co-contraction) and feedback muscle controls that is dependent on musculoskeletal dynamics and sensory noise. The efficiency of our framework opens the door for stochastic optimal control simulations of whole body movement such as walking. 
Cerebellar Purkinje cells encode an internal model of vestibular reafference by predicting the consequences of voluntary self-motion 
The ability to distinguish between self-generated (reafference) vs. externally-applied (exafference) sensory signals is fundamental for ensuring accurate motor control as well as perceptual stability. This is particularly evident in the context of the vestibular system, in which the same central neurons that receive direct afferent input also project to motor neurons that control vestibulo-spinal reflexes (VSR). Notably, while VSRs are essential for providing a postural response to unexpected perturbation, they are impeding during self-generated motion. Previous studies by our group have shown that the brain builds an internal model of the expected consequences of voluntary self-motion that cancels the vestibular reafferent inputs to the central VSR neurons in the vestibular and deep cerebellar nuclei. Accordingly, here we recorded from Purkinje cells in the anterior vermis in two rhesus monkeys during comparable active & passive head movements. We first recorded neuronal responses to vestibular-only and neck proprioceptive-only passive stimulation. We found that the Simple spike activity encoded both stimuli in a direction-dependent manner. Accordingly, for each Purkinje cell, we first developed a model of the dynamics of simple spike response based on passive head and body movements kinematics in each direction. We then passively applied both vestibular and proprioceptive stimuli simultaneously (i.e., passive head-on-body rotations) and found that Purkinje cells linearly integrated these two inputs. Then to compare each neuron’s responses to active versus passive movements, we fit comparable models to neuronal responses during preferred and non- preferred active head movements. We found that neuronal sensitivities were markedly attenuated in the active condition (~60%, p<0.01). The reduction in single Purkinje cells modulation during active motion is surprising given they inhibit the vestibular nuclei/deep cerebellar nuclei. However, our modeling suggests that the cancellation signal could be explained by the convergence of a population of Purkinje cells. Finally, we tested whether the attenuated responses during the active movement is a result of neck motor inputs to the Purkinje cells. We found that while in the majority of the Purkinje cells, the neck motor signals affect the simple spike firing, a simple linear model that integrates motor signal with the sensory feedback cannot explain the suppressed simple spike response during active movements. Taken together, these results provide new insights into the computations performed by Purkinje cells in the anterior vermis that could underlie the generation of an internal model involved in vestibular reafference suppression. These findings suggest that (i) single cerebellar Purkinje cells implement nonlinear sensorimotor integration to differentially encode active vs. passive head movements and (ii) the population of Purkinje cells cancel vestibular reafference signal in their targets. 
Proprioceptive cortex provides veridical feedback of arm movement and forces during force field adaptation 
The brain readily adapts its motor output to facilitate movement in changing environments, like reaching movements made above or below water. Adapting such movements requires both flexible motor output and reliable feedback about the movements themselves and the external forces acting on the body. Most previous adaptation studies have focused on behavioral data, although a few have examined how motor regions change in these contexts. To our knowledge, no electrophysiology studies have examined the role of proprioception - the sense of body position, movement, and forces - in motor adaptation. Sensory feedback about the state of the body is critical to correct movement errors and somatosensory cortex is necessary for motor learning in monkeys, cats, and mice. However, it is still unclear whether proprioceptive somatosensory cortex is itself adapted or continues to provide veridical feedback about the adapting movements. To address this gap, we studied neural activity from somatosensory and motor cortex as monkeys adapted to planar reaching in a viscous curl field. We recorded the spiking activity of populations of neurons in Brodmann’s area 2 - a proprioceptive area of somatosensory cortex - along with similar recordings in primary motor cortex (M1) and dorsal premotor cortex (PMd). We explored the encoding of movement errors in area 2 by training movement direction decoders in a null field condition and testing during the force field and washout epochs. We then compared the results from area 2 to those from M1 and PMd. Unlike the motor areas, area 2 displayed only abrupt changes in decoding performance corresponding to the onset and offset of the curl field epochs. We studied these changes in a population of simulated neurons driven by modeled muscle spindles and concluded that they were largely input-driven effects, not related to intrinsic changes within area 2. Further, area 2 consistently represented a series of passive movements applied to the arm between trials throughout adaptation. To examine neural changes throughout adaptation more closely, we used demixed principal component analysis (dPCA) to extract dimensions within the population activity that covaried with the state of adaptation, treating the sensory and motor regions independently. We found that adaptation- related dimensions accounted for 13% of the variance in M1 and 14% of the variance in PMd throughout exposure to the force field and washout. In contrast, adaptation-related dimensions accounted for little variance in area 2 (3%). Together, these results suggest somatosensory cortex plays a unique role in adaptation. While motor areas of cortex alter their intrinsic activity, presumably reflecting the formulation and execution of a new motor plan, area 2 maintains consistent representation of the movement and forces on the arm, likely providing veridical feedback about movement error -- a necessary element for adapting movements to new environments. 
Evidence for a common mechanism supporting invigoration of movement and perceptual decision-making 
The speed of our movements - often referred to as ‘vigor’ - can vary depending on circumstances. In particular, it is well established that the promise of earning a reward leads us to move faster. Potential rewards also lead to lower reaction times (RTs), suggesting that the process of deciding where to move and preparing the movement can also be invigorated by reward. Normative computational theories have outlined how both the vigor of movement and the speed of decisions may be determined by optimizing analogous trade-offs between available rewards and the costs of acting or deciding more quickly (Manohar et al., 2017). It has also been proposed that there may be a mechanistic link between movement vigor and decision speed, via a common underlying neural mechanisms responsible for determining both (Thura, 2020). Evidence in favor of such a shared mechanism is inconclusive, however (Reynaud et al., 2020). Although reward seems to be a reliable way to elicit changes in movement vigor, it is not the only way that movement vigor can be altered. People can easily voluntarily vary the speed of their movements if instructed to do so. It is unclear, though, how this might affect the speed of their perceptual decision making. If decision-making and movement vigor do indeed share a common mechanism of invigoration, then instructing people to vary their movement speed ought to also affect the speed of their decisions. To test this, we performed an experiment in which we required participants (N = 12) to perform center-out reaching movements to shoot through targets presented at unpredictable locations. In different blocks, participants were asked to move at different speeds (slow ~0.31 m/s, medium ~0.55 m/s, or fast ~1.00 m/s). We assessed their perceptual decision- making ability in each block by using a forced-reaction-time approach to assess how rapidly they were able to identify the target location and prepare the appropriate movement (Haith et al., 2016). Specifically, participants were required to initiate their movement synchronously with a metronome and we varied the amount of preparation time they were allowed by presenting the target at different delays prior to the time of movement initiation. This yielded a speed-accuracy trade-off, from which we estimated the average speed of preparation by fitting a cumulative Gaussian distribution to this trade-off. Estimated preparation times in the slow condition (211.2 ± 8.6ms) were significantly longer than in the medium (180.1 ± 6.0ms) and fast (182.3 ± 7.2ms) conditions (p < 0.01), suggesting that instructing participants to move more rapidly also caused them to detect the target location and prepare their movements more rapidly, even though this was not instructed. Our results provide evidence in support of the hypothesis that urgency in decision making and invigoration of movement may be guided by a common underlying mechanism. 
Rapid motor responses reflect explicit sensory and goal-related priors 
As we move through the world, the brain must constantly integrate new sensory information with our prior expectations so that we select the most appropriate action to achieve our goals. Many reaching experiments have demonstrated that contextual information can modulate the magnitude of rapid feedback responses (40- 105ms, referred to as long-latency) in arm muscles following unexpected mechanical perturbations and that cortical processing plays a key role in these responses. Furthermore, these rapid responses do not simply reflect a final movement decision, but rather continually reflect an ongoing noisy decision-making process. However, it’s unclear whether trial-to-trial changes in prior expectations about potential goals and sensory information can be immediately integrated into our rapid muscle responses. To address these questions, we performed two experiments in which human participants were seated in a planar robotic exoskeleton (KINARM) and given explicit visual cues on each trial about the probability of which of two goal targets they would have to move to following an elbow perturbation (Experiment 1, N = 14), or which of two elbow perturbations (i.e., flexion or extension) they would encounter before moving to a target (Experiment 2, N = 20). Each target location or perturbation direction had a variable probability cued by differently sized arrows (0%, 25%, 50%, 75%, 100%), and perturbations were applied such that the hand was pushed into or away from the goal target. In both experiments, the kinematic trajectory of the hand following perturbations away from the target was modulated by the cued target and perturbation direction probability, showing the fastest movements for expected conditions and the slowest responses for unexpected conditions. Crucially, we found that rapid responses in the arm muscles that were stretched following perturbations that moved the hand away from the target linearly scaled with the cued probability of that condition within ~70ms of the perturbation. These results could not be explained by anticipatory muscle contraction before the perturbation, which were not significantly different between probability conditions, nor by participants ‘guessing’ on individual trials. These findings show that long-latency muscle responses flexibly reflect prior information about movement goals and sensory expectation, allowing the motor system to rapidly prepare the appropriate repertoire of motor responses depending on context. Future studies will examine how cortical circuits may facilitate the integration of incoming visual and somatosensory information with priors to continually control movement. 
Motor preparation contribution to express visuomotor responses in human upper limb muscles 
The cerebral cortex can predict future events from contextual cues, thus facilitating the initiation of stimulus- directed responses. Notably, although the complex computations of cortical sensorimotor networks limit the minimum response onset time, humans can produce express visuomotor muscle responses encoding the location of visual stimuli within 80-100ms of their presentation (stimulus-locked responses, SLRs). The rapidity and inflexibility of SLRs suggest subcortical visuomotor transformations, potentially via the tecto-reticulo-spinal pathway. Recent data that SLRs are facilitated by increased predictability of stimulus timing and location suggests that the putative subcortical SLR network is modulated by cortical top-down expectations. An open question is at what stage cue-induced SLR modulations exert their effect along sensory-to-motor transformation within the putative subcortical SLR circuit. For example, cue-induced SLR effects might be due to pre-stimulus preparation of expected movements, or facilitation of sensorimotor transformation of expected stimuli. We recorded EMG activity from shoulder muscles while 16 subjects made right or left horizontal arm movements to address targets at one of four locations: (I) right-top; (II) right-bottom; (III) left-top; (IV) left-bottom. Thus, a single uniplanar right, or left, reach was required for both top\bottom targets in the right, or left, hemi-field. On each trial, a symbolic arrow cue appeared on the central fixation spot >1s before target presentation and pointed toward one of the four possible target locations. The arrow cued the right\left target location with 75% validity. The top\bottom location was cued with 75% validity for valid right\left cue conditions, and 50% validity for invalid right\left cue conditions. Validly cueing the right\left target location led to significantly more SLRs (13/16 subjects) than invalid cues for reach direction (5/16 subjects). When the reach direction was validly cued, SLR initiation time (~87ms) and magnitude (~74μv) were similar for both targets on the vertical axis, irrespective of top\bottom cue validity. Thus, cue-induced expectations about the vertical target location did not modulate the SLR. The fact that both target locations on the vertical axis required the same movement could promote the preparation of a single motor response compatible with the cued reach direction. This could have facilitated the integration of motor signals with any visual input appearing congruently with the prepared response within the putative subcortical SLR pathway, irrespective of the top\bottom cue validity. Our results are consistent with a motor preparation contribution to SLRs, however, a broad top-down priming of the collicular visual map that encodes the cued hemi-field is not excluded. Further studies are necessary to disentangle motor preparation and spatial visuomotor facilitation contributions to express visuomotor responses. 
Control of movement deceleration by the Purkinje cells of the cerebellum 
Damage to the cerebellum affects many aspects of behavior, including the ability to precisely end a movement. This suggests that Purkinje cells might control movement termination. Yet, Purkinje cell activity is modulated long after movement ends. Recently, we hypothesized that the fundamental unit of computation may be a population of Purkinje cells that share the same preference for error, i.e., the input from the olive organizes Purkinje cells into groups. We recorded from the oculomotor vermis of the marmoset cerebellum during visually guided saccades. Each trial started by jumping the target in a random direction. Upon detection of the primary saccade, we induced an error by jumping the target again. Subjects experienced a sensory prediction error at the offset of the primary saccade and subsequently made a corrective saccade. We recorded from 134 Purkinje cells in two monkeys, including 35 pairs of simultaneously recorded Purkinje cells. Each Purkinje cell had a complex spike response to the direction of target displacement. However, because each target displacement was followed by a saccade, it was unclear whether the complex spike tuning was in response to the sensory event (target displacement) or a prelude to a movement (saccade). To disentangle the possibilities, we measured saccades that were not driven by target displacement. Without the sudden appearance of a visual stimulus, saccades were not preceded by a complex spike. Thus, complex spikes conveyed a sensory prediction error, not a movement error. Using complex spike tuning we organized Purkinje cells and measured their population simple spikes. The population simple spike response exhibited a burst just before saccade onset, then a partial pause during deceleration. Importantly, the pause duration precisely predicted saccade duration. Remarkably, when saccade velocity was lower and duration was longer, the burst that preceded the saccade was smaller, and the pause during the saccade lasted longer, revealing sensitivity to saccade vigor. As the saccade amplitude became larger, the transition from burst to pause became later, demonstrating a sensitivity to the onset of the deceleration phase. Thus, organizing Purkinje cells into populations produced simple spike activity that was a predictor of saccade velocity, direction, and duration. Next, we considered the fact that control of the deep cerebellar nucleus depends not just on the firing rate of Purkinje cells, but also the timing of their spikes. We measured simultaneous activity of 35 pairs of Purkinje cells and found that before saccade onset, and during acceleration, despite the burst of simple spikes the probability of synchrony remained at baseline. However, during deceleration the simple spikes became 30% more synchronized than baseline. In summary, organizing Purkinje cells into populations that shared complex spike tuning resulted in simple spikes activity that was sensitive to the timing of deceleration. Spiking in the population became synchronized during deceleration, suggesting that Purkinje cells play a significant role in predicting how to end the movement. 
Movement variability is actively regulated in speech 
Although movement variability is often attributed to unwanted noise in the motor system, recent work has demonstrated that variability may be actively controlled. Specifically, baseline variability in upper limb control can be selectively increased and decreased depending on task demands. To date, research on regulation of motor variability has relied on relatively simple, laboratory-specific reaching tasks. It is not clear how these results translate to complex, well-practiced, real-world tasks or to actions controlled via non-visual feedback. Here, we test how variability is regulated during speech production, a highly over-practiced motor behavior that relies on auditory and somatosensory feedback. Separate groups of healthy speakers were exposed to a real-time auditory perturbation designed to affect the perceived variability of their speech. The inward-pushing group (N=24) received a perturbation that shifted every production towards the center of that participant’s distribution for each vowel (the vowel “targets”). The outward-pushing group (N=22) received the opposite perturbation, a shift of every production away from these targets. As a control, we analyzed an existing dataset with no auditory perturbation (N=25). As expected, the control group showed no change in variability over the course of the experiment. Participants exposed to the inward-pushing perturbation consistently increased produced variability while the perturbation was applied ( 5.0 mels, p < 0.001) as well as after it was removed ( 4.4 mels, p < 0.001). Further, in this group, baseline variability was predictive of the change in variability (p < 0.001): participants with lower variability in the baseline phase showed larger variability increases. This suggests that lower perceived variability “frees” the motor system to be less precise. Unexpectedly, the outward-pushing perturbation also increased produced variability ( 4.3 mels, p = 0.001), but inconsistently across different vowels and dimensions of control; variability returned to near baseline levels when the perturbation was removed ( 2.2 mels, p = 0.125). Variability changes were not predicted by baseline variability. These results are consistent with a state-space model of motor adaptation that corrects for trial- to-trial errors without any changes in intrinsic variability, as those errors are amplified by this perturbation. Indeed, in this group, participants increased vowel centering, a measure of within-trial correction (movement toward the median from vowel onset to vowel midpoint), suggesting the perturbation resulted in an increased sensitivity to errors in feedback. The lack of observable decreases in variability in response to the outward-pushing perturbation differs from previous results in limb control and suggests speech may naturally be produced at the lower limit of possible variability. Together, these results suggest that variability, even in complex tasks such as speech, is actively regulated. 
The mouse nucleus propositus relays eye movement information to head direction network during navigation 
The vestibular system plays a crucial role in our everyday life as it ensures gaze and postural stabilization and the sense of self-motion by detecting the head motion in space. Previous work done in rodents (i.e. mice and rats) has led to the view that the nucleus prepositus hypoglossi (NPH) and the supragenual nucleus (SGN) in brainstem relay vestibular information from the vestibular system to the head direction (HD) network. However, the NPH has also been long-known to comprise the oculomotor integrator, which plays an essential role in eye movement control by holding the eye at an eccentric position in orbit after the saccade. Further, a study in non-human primates (Dale & Cullen, 2013) established that neurons in the NPH predominantly encode eye-related rather than head-related movement signals during both passively-generated and voluntary head movements. To date, however, it remains unknown whether neurons in the NPH of rodents encode eye-related and/or head-related movement signals. We hypothesized that NPH neurons in mouse, as in primate, preferentially encode eye-related signals during passive- generated and voluntary movement. Accordingly, we recorded the activity of NPH neurons with both with tungsten electrodes and/or 960 recording-site Neuropixel probes. Eye movement was simultaneously recorded with an AMR magnetic field sensor. Head-retrained behavioral protocols (Beraneck & Cullen 2007; Medrea & Cullen, 2013) including vestibular-ocular reflex (VOR), optokinetic reflex (OKR), and changes in static eye position (SEP) to dissociate eye and head movement sensitivities. Our preliminary results indicate that neurons in the NPH of mice primarily encode eye-related information during both passive and active head movement. Notably, neurons demonstrated a nonlinearity that consisted of a decrease in gain with increasing amplitude. Overall, our results provide the first evidence that NPH neurons primarily encode eye movements rather than head movements in mice. Thus our findings suggest that NPH neurons relay an eye-related signal to the HD network. 
Pitfalls in quantifying exploration in reward-based motor learning and how to avoid them 
In reward-based motor learning, humans have to learn a movement based on binary success information. An essential aspect of this learning is to explore one’s possibilities to obtain reward. How can we quantify this exploration? Interpreting parameter estimates from models fitted to actual learning data is complicated. Therefore, we developed a simple method to estimate exploration. Humans have been shown to be more variable following failure than following success. If one assumes that variability following success reflects inevitable motor noise, the additional variability post failure will reflect exploration. When studying changes in average behavior (as in reward-based motor learning), variability can best be estimated from trial-to-trial changes in movements. Can we estimate the exploration reliably from such trial-to-trial changes? To answer this question, we determined whether our method could reconstruct the exploration underlying learning as described by four existing reward- based motor learning models. We simulated learning for various learner and task characteristics and estimated exploration. If we simply determined the additional variability in subsequent trials, this method appeared to be sensitive to learner and task characteristics. We identified two pitfalls in quantifying exploration based on trial-to- trial changes. Firstly, the use of performance-dependent feedback can cause correlated samples of motor noise and exploration on rewarded trials. This biases these estimates of exploration depending on the balance between motor noise and exploration. Secondly, the trial relative to which trial-to-trial change is calculated may or may not contain exploration. As a result, the difference in trial-to-trial changes underestimates exploration. To circumvent these problems, we developed the additional trial-to-trial change (ATTC) method. By moving the reference trial one trial back and subtracting trial-to-trial changes following specific sequences of trial outcomes, exploration can reliably be estimated for three of the four models that we used. This allows for model-free estimation of exploration if humans regulate exploration based on binary trial outcome. The ATTC has some limitations. It does not provide reliable results if exploration depends on a history of trial outcomes, rather than only on success in the previous trial. Furthermore, it requires experiments with a high number of trials since only specific trial sequences contribute to ATTC estimates of exploration. As a result of the pitfalls we identified, comparing trial-to-trial change-based variability estimates post failure and post success as reported in the literature may give a biased impression of actual exploration. In conclusion, if exploration is a binary function of the outcome of the previous trial, the ATTC method allows for a model-free quantification of exploration. 
Monkeys exhibit flexible control strategies in a virtual balancing task 
Our current understanding of arm movement control comes primarily from studies involving simple behavioral tasks, like point-to-point reaches. However, many of the movements we make with our arms are not simple, requiring continual sensory feedback to perform adequately. To study the neural control of more natural movements, we must begin exploring behavior during highly feedback-driven tasks. An example of such a task is balancing a pole on your palm, where you must continually make adjustments to prevent the pole from falling, and each balancing attempt is unique. Such a task provides an ideal window into how the nervous system generates the constant feedback-driven adjustments necessary for many real-world behaviors. We trained monkeys to perform a virtual, visually-guided balancing task. The task started with a cursor, analogous to the tip of the pole, in the center of a screen. The cursor position was inherently unstable--at each time step, the cursor velocity was proportional to the sum of the cursor position and the monkey’s hand position. In essence, this means that without any arm movement, the farther the cursor went to one side, the faster it would go towards the edge of the screen. The monkey’s goal in the task was to counteract the movement of the cursor with that of its hand, keeping the cursor within 5 cm of the center for 6 seconds. Arm movements on individual trials were highly varied, and no two trials were identical. This behavioral richness made it unsuitable for typical trial-averaged neural analyses. Instead, we began by carefully analyzing the behavior on individual trials. Within individual trials, monkeys seemed to switch between qualitatively different control schemes, suggesting that they may have had different movement goals at different times through a trial. We assessed this hypothesized control-switching model by fitting the arm movement with a switching linear dynamical system, using the cursor position and velocity as inputs. This resulted in three interpretable control schemes: 1) simple restoration, which involved tracking the cursor to bring it back to center; 2) rescue movement, which involved a quick movement to stop the cursor in place; and 3) sensory deadzone, where the monkey held the hand still in response to low cursor velocity. A primary goal of this work is to understand the neural underpinnings of highly feedback-driven behavior. Our control-switching model of behavior suggests that neural activity may also exhibit similar switching behavior, with each state exhibiting different neural signatures. For example, a rescue movement may carry a neural signature similar to that of a discrete reach, with separate planning and execution phases. Through ongoing work, we intend to explore how our behavioral model informs cortical activity as monkeys perform this highly feedback-driven task. 
Prefrontal-motor and somatosensory-motor cortical network interactions during reactive balance are associated with distinct aspects of balance behavior in older adults 
Heightened reliance on the cerebral cortex for postural stability with aging is a well-known but poorly understood phenomenon. Cortical activity and interactions between cortical regions that may underpin behavioral aspects of balance ability most closely linked to falls in older adults is unclear. Here we investigated the relationship between motor cortical activity, measured as beta power, and circuit-specific cortico-cortical interactions, measured as beta coherence, versus behavioral assessments of different aspects of individual balance ability. Using electroencephalography (EEG), we assessed motor cortical beta power and beta coherence between prefrontal and somatosensory regions with motor cortical regions during standing balance recovery reactions to support- surface perturbations in a group of older adults (n=15). First, we found that individuals with greater balance performance decline during a concurrent cognitive dual task elicited unintentional stepping reactions at lower perturbation magnitudes during single-task performance. Perturbation-evoked increases in beta power over motor cortical regions were negatively associated with general clinical balance function, measured by the miniBEST. While beta coherence between somatosensory and motor cortical regions did not change during balance reactions, greater somatosensory-motor coherence during baseline standing posture was associated with higher clinical balance function. At the group-level, beta coherence between prefrontal and motor cortical regions reduced during balance reactions. Older adults with the highest post-perturbation prefrontal-motor coherence showed greater cognitive dual task interference and had lower individual thresholds for eliciting stepping reactions in response to perturbation. Consistent with findings in younger adults, our results support motor cortical beta activity as a potential biomarker for individual level of balance challenge in older adults. Our findings identify distinct interactions between prefrontal and somatosensory regions with the motor cortex linked to specific aspects of balance behavior in older adults. Prefrontal- and somatosensory-motor cortical networks could potentially serve as effective neural targets for precision-medicine efforts aimed at fall-prevention in older adults based on individual behavioral and neurophysiologic deficits. Our results further suggest that prefrontal-motor cortical network recruitment is a common neural substrate underpinning cognitive dual-task interference and the upper-edge of individual reactive balance capacity, which are strong behavioral predictors for falls. 
High-bandwidth transmission to the ventral intermediate (VIM) nucleus from peripheral stimulation highlights possibility of non-invasive treatment for children with movement disorders 
High-frequency peripheral nerve stimulation has recently emerged as a noninvasive alternative to thalamic deep brain stimulation (DBS) for treatment of essential tremor, but has not yet been investigated for use in childhood movement disorders, such as dystonia. Since stimulation in the thalamic ventralis intermediate nucleus (VIM) has been clinically helpful in a subset of dystonic children, it is possible that a similar benefit could be obtained noninvasively, conditioned upon peripheral stimulation providing reliable activation of VIM. We hypothesize that this condition is in fact met, based on the theory that precise, stable motor control requires high-fidelity, high-speed, and low-latency transmission of sensory information, including proprioceptive and tactile signals. While the human voluntary motor output is estimated to have an update frequency of around 10 Hz, sensory responses may operate at a higher frequency. For example, to determine the onset of touch, the response rate must be at or above 10 Hz, with periods shorter than the reaction time. Therefore, transmission of high temporal frequency signals is important in peripheral sensation, and the speed of transmission must be rapid, above 50 m/s. We investigated this hypothesis by exploring the frequency response and transmission delay in high-speed pathways that convey proprioception to the sensory thalamic nuclei via cerebellum, in 10 pediatric patients undergoing DBS for dystonia. We used a new technique for DBS targeting in children with dystonia, allowing for simultaneous recordings from multiple thalamic nuclei while stimulating peripherally. Sensory evoked potentials (SEPs) were recorded during stimulation of the median nerve at the wrist based on monophasic 1-ms pulses at 5 Hz, or as bursts of 100-ms pulse trains at 50 Hz, 100 Hz, 140 Hz, or 170 Hz, repeated every 200 ms (5 Hz) during a period of 4 minutes for each train. As expected, only the primary sensory thalamic region (VIM) has a robust SEP to burst stimulation at 5 Hz, whereas secondary projection regions (ventral oralis anterior/posterior, Voa/Vop, or ventral anterior, VA) do not. Our results show that the sensory output is able to represent stimulus frequencies at least as high as 170 Hz, with a peak sensitivity between 50 Hz and 100 Hz, and short transmission delay of 12-14 ms, in most children. This high-bandwidth, low-latency transmission path from the median nerve to thalamus is consistent with our hypothesis that rapid and accurate sensory information is vital for the control of coordination and movement via the cerebello-thalamic pathway. This in turn supports the possibility of noninvasive modulation of thalamic activity in children with dystonia, meaning that a subset of children could have clinically beneficial response through peripheral stimulation, which is safer, cheaper, and more accessible than the currently used invasive deep brain stimulation. 
Data-driven models of stroke gait dynamics can discriminate individual differences better than discrete gait descriptors 
In people with post-stroke hemiparesis, there is considerable heterogeneity in gait impairment that is not sufficiently captured by common descriptors of gait. Moreover, to optimally augment gait dynamics using technological devices such as exoskeletons, predictive dynamical models of gait are essential. Currently, researchers typically collect gait kinematic and kinetic data across multiple gait cycles, but the data are usually reduced to discrete summary variables (e.g. peak anterior ground reaction force), ignoring the continuous biomechanical dynamics that generate them. Recurrent Neural Networks (RNNs) with long short-term memory (LSTM) can generate complex sequences and predict the future dynamics of a system. We hypothesized that individual differences in gait could be captured by the internal parameters of an RNN trained on kinematic data; we call these “RNN gait signatures”. We tested whether individuals with and without stroke could be discriminated against using RNN gait signatures. We formulated three different gait data descriptors for each 45s walking trial of each individual (5 able-bodied, 8 stroke survivors) and gait speed (6 each): 1) 26 discrete summary variables (13 averaged variables for each leg), 2) Six phase averaged joint angles (bilateral hip, knee, and ankle flexion angles) and 3) RNN gait signatures. To develop RNN gait signatures, we trained an RNN model using continuous joint angles of all trials. For each trial, we extracted the model’s internal activations, applied principal component analysis, and phase-averaged the first 6 principal component magnitudes. Support Vector Machine (SVM) classifiers were used to discriminate gait groups (able-bodied or stroke) or individuals for each data type. Overall, RNN gait signatures more accurately discriminated groups and individuals than either discrete summary variables or joint angles. SVM classification accuracy was 100% for both RNN gait signatures and discrete variables, and higher using RNN gait signatures compared to joint angles (93.9 ± 4.1%, p << 0.001). SVM classification of individuals was most accurate using RNN gait signatures (99.4 ± 2.3%), only slightly lower using discrete variables (98.0 ± 4.0%, p < 0.007), and considerably lower using kinematics (83.8 ± 8.7%, p <<0.001). Notably, RNN gait signatures could discriminate between gait groups with similar accuracy as discrete variables which include both kinematic and kinetic measures. RNN gait signatures outperformed kinematics in distinguishing individuals, suggesting that RNN models implicitly capture force to motion relationships that kinematics data alone cannot. Improving our ability to distinguish gait characteristics post- stroke using RNNs may enable the development of individually-tailored rehabilitation interventions to improve gait. 
Grip-specific neural population dynamics are not shared between action and observation in the frontoparietal cortical grasping network 
Neurons in the frontoparietal cortical grasping network respond during both the execution and observation of an action. This observation has been used to support numerous theories linking motor control and cognition but remains poorly understood at the neuronal population level. To address this, we use chronic multi-electrode arrays to record simultaneously from neuronal populations in the macaque primary motor (M1), premotor (F5), and posterior parietal (AIP) cortices as animals either grasp a variety of different objects or observe a human subject doing the same. We find a lack of distinct functional neuronal classes in any of these cortical areas; instead, neurons exhibit a continuum of preferences for action and observation. The lack of clear neuron classes affirms that the link between action and observation may indeed be better understood in the framework of neuronal state space. Using targeted dimensionality reduction techniques, we find dimensions of neural activity that are shared between action and observation contexts, which decrease in prominence from AIP to F5 to M1. However, this shared activity does not include a shared representation of grip type, as assessed using classification methods that allow for response scaling and latency differences between the two contexts. We also fit linear dynamical systems to these data and fail to find a common dynamical structure underlying the disparate grip representations between action and observation. Activity during observation therefore lacks congruence with the precise grip-specific representations and dynamics seen during action. These results suggest that the link between action observation and action execution is weaker than anticipated in the frontoparietal network. 
Sparse subspace analysis - a dimensionality reduction tool to find interpretable neural subspaces within and between populations 
Populations of neurons exhibit diverse and dynamical patterns of activity that are associated with different behaviors and internal states. For example, the correlation structure of motor cortex neurons’ activities completely changes between planning and movement. Typical dimensionality reduction techniques, like PCA, find entangled low-dimensional representations in which individual dimensions reflect a mixture of the structure found in different behaviors (e.g. a mixture of planning and movement-related activity). This generally precludes interpreting individual dimensions and understanding which modes of activity are unique to different behaviors, which are shared, and which are unrelated to known behavior. Here, we introduce sparse subspace analysis (SSA), a dimensionality reduction method that aims to find interpretable low-dimensional representations, or neural subspaces. SSA encourages the low-dimensional representation to be sparse so that it finds dimensions that are only used at sometimes (e.g. only during planning or movement). Importantly, SSA is not only designed for single populations, but is also able to find more interpretable shared subspaces between neural populations, enabling a clearer understanding of how shared structure changes over time. To verify our approach, we first demonstrate in simulations that SSA leads to more disentangled low-dimensional representations than PCA and reduced rank regression (for one and two neural populations, respectively). Crucially, this increased interpretability does not significantly impact our ability to accurately reconstruct the neural activity. We next demonstrate the utility of SSA on multiple datasets. SSA, which only receives neural activity (and not behavioral data) as input, is able to rediscover that 1) the motor cortex activities used for movement and planning reside in separate dimensions; and 2) activities shared from dorsal premotor cortex to primary motor cortex reside in separate dimensions during planning and movement. We finally use SSA to uncover that dorsal premotor cortex represents movement uncertainty using the same neural subspace in which planning occurs. Our results demonstrate how SSA is a valuable tool for researchers to probe their data to find interpretable modes of neural activity within and across populations. 
The energetic basis for smooth arm movements 
Introduction Reaching is thought to be governed more by kinematics than energetics or dynamics. The variance of the hand’s position is affected by signal-dependent noise (Harris & Wolpert, 1998), and is reduced if reaching movements are smooth. But energetic cost could also affect reaching, since metabolic cost decreases during adaptation (Huang & Ahmed, 2012). But, known contributions to energetic cost in reaching, such as mechanical work, fail to explain the smooth reaching motions observed empirically. However, other aspects of muscular energy cost might explain smoothness. Motions such as human rhythmic leg swinging (Doke & Kuo, 2007) reveal a less- appreciated cost for rapidly changing muscle activation and its associated calcium transport (Chastiosis, 1987). The cost per contraction is predicted to increase with force rate (time-derivative of force). We hypothesized that force-rate could also apply to reaching and explain its metabolic cost. We used a cyclic reaching task to test this hypothesis and applied that cost in an optimal control model that predicts smooth reaching. Methods Subjects (N=10) performed bimanual planar reaching movements about the shoulders (KINARM). Cyclic movements were made between two targets, and amplitude and frequency were varied together to increase force-rate but fix mechanical work. We estimated metabolic power using respirometry and tested its dependence on the hypothesized force-rate cost, plus a cost for average positive mechanical power. Results & Discussion Energy expenditure increased substantially with the hypothesized force-rate cost. Net metabolic rate increased 3.6-fold, from about 5.3W to 19.0W across frequencies ranging from 0.58 Hz to 1.36 Hz. Average positive mechanical power was approximately constant, force amplitude increased slightly (1.33 fold), and movement speed decreased. Energy cost could not be explained by work, force, or speed, but was linear with force-rate. The cost from force-rate was small (less than 5%) at low frequencies, but large (73%) at the highest frequency (peak speed 0.4m/s). We applied this cost to optimal control of discrete, fixed duration movements (Harris and Wolpert 1998) minimizing the energy cost derived from our experiment. Optimal trajectories were smooth and closely resemble those predicted for variance. Present models (Uchida et al. 2016) do not include a force-rate cost and cannot explain the empirical findings. Accuracy (movement variance) remains an important factor in reaching but is not needed for smoothness. Effort/energy have also been proposed as factors (Todorov & Jordan 2002, Uno et al. 1989) but lacked a physiological mechanism such as force-rate. Energy minimization may explain decreasing expenditure with adaptation, and speed-mass relations (Bruening et al. 2019). Finally, it increases the compatibility of arm movements with locomotion (Kuo et al., 2005) and other animal behaviors (Alexander 1996), where energy expenditure is thought important. 
Stiffness perception is scaled according to asymmetrical hemispherical maps 
Estimating object’s stiffness is usually done by squeezing it using one or both hands. Since we lack stiffness sensors, the sensorimotor system relies on information about the amount of object deformation and the magnitude of the interaction forces to estimate stiffness. However, the way that the sensorimotor system processes these multi-dimensional, time-dependent signals into a single quantity is still unknown. Here, we compare stiffness perception between the hands, and propose new evidence for such mechanism, and specifically, a difference between the hemispheres in stiffness estimation. One way to estimate stiffness while considering the information of the entire interaction with the object is by calculating the relation between force and deformation. There are two ways to calculate these relations as an estimation of stiffness or as an inverse of the estimation of compliance. Ideally, both estimations yield the same value. However, due to neural delay in the sensory feedback the linear relation breaks resulting in an overestimation of the inverse compliance and an underestimation of the stiffness compared with the nominal stiffness level. The sensorimotor system can calculate a weighted average between those estimations, and equal weights will result in the nominal stiffness level; yet uneven weights do not necessarily mean that the stiffness perception must be biased as the absolute difference between estimated values can remain correct. Perceptual biases will be revealed 1) if additional delay is introduced [Lieb at el.2018] or 2) if there is asymmetry between the hemispheres such that the weights for each hand are different. If the first hypothesis is true, we expect an underestimation of objects that are touched with the left hand compared to the right hand. However, if the second hypothesis is true, participant’s stiffness perception will be biased so that an identical internal delay could even cause to an overestimation of the stiffness of objects that are touched with the left hand compared to the right hand. In our experiment, right- and left-handed participants examined the stiffness of pairs of objects, standard and comparison objects. They either touched both objects with the left or right hand or touched each object with different hand. Participants held a robotic device in each hand, and experienced force feedback proportional to the amount of object deformation. After interaction with both objects, participants were asked to report which object feels stiffer. For left-handed participants, we found no perceptual bias in stiffness estimation across all conditions. However, for the right-handed participants, when the comparison and standard objects were examined using different hands, we found an overestimation of objects that were probed with the left hand compared to the right hand. These results together with our observation from Leib at el.2018, can only be explained by asymmetric processing between the hemispheres. 
The role of parvalbumin expressing neurons in the spinal cord deep dorsal horn (dPVs) in multimodal sensory processing for locomotion 
How does our brain process sensory information to shape behavioral responses? To tackle this fundamental question, we must have a mechanistic understanding of neuronal networks that integrate diverse sensory modalities and transform them into neural codes of motor action. The spinal cord, harboring both sensory and motor circuits, is well-suited to exploring questions about sensorimotor integration. Indeed, a direct link between sensory input and motor output has been demonstrated by Sherrington’s pioneering work on the proprioceptive reflex pathway. However, it is unclear whether spinal cord circuits can integrate different modalities of sensory input required for modulation of complex motor actions such as locomotion. During locomotion, tonic information about muscle tension and speed from proprioceptors must integrate with phasic input from touch receptors in the skin to adjust motor response. Interestingly, the two sensory modalities converge in an area of the spinal cord called the deep dorsal horn, known to contain a large pool of pre-motor neurons. This suggests that interneurons in the deep dorsal horn participate in multimodal sensorimotor processing for locomotion. Using genetic tools in the mouse, we identified a group of deep dorsal horn Parvalbuin expressing interneurons (dPVs) that represent ~30% of the neurons in the area. Combining intersectional genetics, imaging and functional experiments, we demonstrate that dPVs are inhibitory neurons that integrate touch and proprioceptors inputs to directly contact motor neurons. Equipped with a better understanding of dPVs input and output connections, we asked whether this circuit participates in motor performance. Utilizing intersectional genetics and pharmacology, we induced ablation of dPVs in mice (dPVOFF), while their littermates in which dPVs were intact (dPVON) were used as controls. When tested on a balance beam assy, dPVOFF mice did not show a change in the number of foot slips. However, dPVOFF tended to cross the beam faster than dPVON mice. Finally, to characterize dPVs’ role in locomotion, mice walked on a treadmill at speeds ranging from 10 to 80 cm/s, while all four paws were videotaped from below. dPVOFF mice showed an increase in stride frequency during high speed, but not low speed locomotion. Taken together, our results suggest that during high speed walk, dPVs regulate the duration of the step cycle in response to incoming phasic cutaneous input. 
Characteristics and stability of sensorimotor activity driven by isolated muscle activations in a human with incomplete tetraplegia 
Somatotopy and stability of movement representations in the sensorimotor cortex is fundamental to how motor control is encoded and crucial for brain-machine interfaces (BMIs) that decode these representations into motor output. Previous characterizations considered body map composition and stability separately, with those looking at changes over time typically limited to injury (e.g. stroke) or targeted interventions (e.g. intense motor training). Here we characterized the bilateral sensorimotor map associated with isolated muscle contractions in a quadriplegic human and its stability across short (minutes) to long (day) time intervals. To construct the map, we concurrently recorded surface electromyograms (EMG) with multiunit activity (MUA) in bilateral primary motor (M1) and somatosensory (S1) cortices in a quadriplegic as he executed (or attempted to execute) different isolated muscle contractions across the entire body (56 muscles). To assess stability, we repeated isolated motor contractions of the intact extensor carpi radialis (ECR) on the orders of minutes, hours, and days. For each measurement period, we compared 3 stability metrics: (1) spatial stability of somatotopy, defined by the frequency that small cortical areas remained active over time; (2) firing pattern stability, defined by the amplitude and shape of MUA, and (3) graded-spatial stability, defined by the consistency of firing strength across the map. Isolated muscle activations across the entire body revealed significant M1 and S1 MUA for arm muscles (intact and de-efferented), sparse activity for head and core muscles, and no activity for muscles below the trunk, with latency patterns in M1 preceding those in S1. The majority of MUA coded exclusively for contralateral muscle contractions (85%), with lesser MUA coding exclusively for ipsilateral (5.3%) and bilateral (14%) muscles. Stability of the cortical ECR representation uniquely varied over the period of consecutive measurements and by brain area. Spatial stability significantly declined on the order of hours, though longitudinally it was higher in sensory than motor areas and higher for contralateral than ipsilateral hemispheres. Likewise, firing rate stability declined on the order of minutes to hours with greater stability in S1 than M1 MUA. In contrast, graded-spatial stability was maintained for longer intervals compared to stability metrics of either spatial or firing rate alone. Together, these findings suggest that MUA in M1 and S1 codes multiple regions on both sides of the body, in a fractured and partially overlapping arrangement with sensory and contralateral areas consistently exhibiting higher stability than motor and ipsilateral areas. This is suggestive of M1 (especially ipsilateral) being more malleable over time than sensory areas. Importantly, though MUA activity of the sensorimotor body map changes within hours, when spatial distribution and firing rate are combined, stability becomes more robust. 
Coordination of quadriceps muscles before and after VL paralysis in rats demonstrates neural regulation of joint stresses 
How does the central nervous system (CNS) coordinate redundant muscles during behavior? According to one common proposal, muscle coordination reflects simplification of task performance by the CNS, so that muscles with similar contributions to task variables are controlled together. Here we demonstrate that the coordination between quadriceps muscles in rats better reflects regulation of stresses and strains within the knee. We analyzed co-variation patterns in quadriceps muscle activity during locomotion in rats (Alessandro et al. 2020). The three vastii (vastus medialis VM; vastus lateralis VL; and vastus intermedius VI) produce knee extension and so have identical contributions to task performance. A coordination strategy solely driven by simplification of task performance would therefore predict a similar correlation between the activity of any pair of vasti muscles. Instead, we found that the correlation between VM and VL was stronger than their correlation with VI. This coordination strategy supports the control of internal joint stresses: since VM and VL produce opposing mediolateral forces on the patella, their strong positive correlation minimizes the net mediolateral patellar force. To confirm this interpretation, we chronically paralyzed VL in order to unbalance the mediolateral forces on the patella, producing a medial loading on the patellofemoral joint. While both VM and VI have the same task action as VL, a compensatory strategy based on increasing the activity of VM would further increase medial joint loading. Instead, the CNS compensated for this perturbation by gradually increasing the activity of VI and rectus femoris (RF) over five weeks of adaptation. Since VI and RF have minimal effect on mediolateral patellar forces, this strategy supports the neural regulation of internal joint stresses and strains. In addition, this finding further suggests that VI can be controlled independently from the other vasti muscles. What neural mechanisms regulate internal joint loading? We investigated the role of joint sensory afferents on VM-VL co-variation and on the adaptation after VL paralysis. The temporary inhibition of joint sensory afferents by injection of lidocaine into the knee capsule did not cause significant changes in quadriceps muscle activity, both before and at any time point after VL paralysis. We therefore found no evidence for fast feedback loops mediated by these afferents. Furthermore, this inhibition did not alter the correlation between VM and VL, suggesting that the covariation between these muscles is either specified centrally or involves other sensory modalities. However, lidocaine injections reduced the correlation between VI and both VL and VM, suggesting the existence of multiple mechanisms involved in coordinating vastii muscle activations. Additional work is needed to investigate whether joint sensory afferents mediate long-term adaptation to joint stresses and strains. 
De-noising EMG using dynamical systems models of multi-muscle activity 
Executing movements often requires the production of precisely coordinated, time-varying activation patterns for muscles that may be distributed across the body. Understanding the strategies by which the nervous system selects and generates these patterns remains a central goal of motor neuroscience. Critical to this effort is obtaining estimates of the neural commands to muscles and evaluating how they are related both to task demands and to neural activity in motor related brain areas. However, a key barrier in this evaluation is our ability to interpret noisy electromyographic (EMG) recordings. Standard processing (i.e., rectification and smoothing) treats all high- frequency EMG features as noise and so can omit critical information about dynamic changes in motor commands. Although this is a reasonable approach, determining the appropriate degree of smoothing is challenging and often performed arbitrarily. Less smoothing might lead to more variable signals that are difficult to interpret, while more smoothing may suppress higher frequency features that are relevant to behavior. Moreover, applying a fixed degree of smoothing may not be appropriate as muscle activation can occur at a variety of timescales during the execution of a task. Here we present a novel approach, dynamically-estimated EMG (deEMG), which leverages advances in deep generative modeling using artificial neural networks to de-noise single-trial activity from groups of muscles. As EMG signals are posited to be the output of an underlying dynamical system, accurately modeling these dynamics using artificial neural networks might provide a better estimate of muscle activation. We applied deEMG to recordings in two model systems: (1) rat hindlimb during locomotion and (2) monkey forearm during an isometric force-control task. In both systems, we find that deEMG enables more accurate single trial behavioral predictions than EMG processed by standard filtering techniques. We also find that deEMG functions adaptively to dynamically adjust its frequency response characteristics according to the time course of different phases of behavior, removing the need to define a single fixed cut-off frequency for the entire behavior. Furthermore, deEMG revealed the presence of 10-50 Hz oscillations shared across muscles during isometric force production that were difficult to see using traditional approaches. This precise correspondence between deEMG and behavior at higher frequencies challenges the traditional model of muscles as low-pass filters. Finally, deEMG corresponded closely to simultaneously recorded activity in the motor cortex, suggesting that deEMG preserves correlations to both descending motor commands and behavior. These results show that deEMG reveals subtle features in muscle activity that may otherwise be overlooked, and that it may allow new insights into motor control by elucidating relationships between muscle, brain, and spinal cord activity with high temporal precision. 
A new view on the spinal network mechanisms underlying rhythmic movements 
Most of the investigations on spinal rhythm generation are based on motor nerve recordings and single neuron recordings. Since flexor/extensor-muscles alternate during movements, it is often assumed that the generation is accomplished by neuronal modules that alternate in opposition, which single neuron recordings seem to support. However, here we argue that when many neurons are monitored simultaneously a different picture emerges. We recorded hundreds of neurons from the lumbar spinal cord of turtles during rhythmic scratching and found that, rather than alternating, the neuronal population is performing a “rotation”, i.e. cycling continuously through all phases. Rotational dynamics are observed across trials as well as behaviors. Since such rotation is difficult to explain with existing models of alternating neuronal groups, we propose a new theory that accounts for the rotational dynamics. Using a simplified network model, we show that in spinal networks with recurrent excitatory and inhibitory connectivity, there is no need for pacemaker activity or modular structures. Tonic input to the network controls the rhythm and pattern depending on the task. The model also reproduces other experimental observations and provides a mechanism for multifunctionality. 
Modeling human sensorimotor control for better control of surgical robots 
During everyday interaction with the external world, for example during surgery, our brain graciously deals with a task that control engineers find very challenging – closed-loop control of movement and contact forces with outdated and noisy information that arrives from multiple sensors. Robot-assisted minimally invasive surgery (RAMIS), where a surgeon manipulates a pair of joysticks that teleoperate instruments inside a patient’s body, requires precise control of movement, object and tissue manipulation, and perception. Despite many advantages for both the patient and the surgeon, the full potential of RAMIS and other teleoperation applications is yet to be realized. Two of the major progress-impeding gaps, the lack of touch feedback, and limited knowledge of how to measure skill and optimize training, could be bridged by applying models of human sensorimotor control. We use behavioral studies to investigate how the sensorimotor system integrates information across time, space, and modalities, for movement, object manipulation, and perception, and how the system changes following adaptation and skill acquisition. I will present our recent results on integration of tactile and kinesthetic information during interaction with virtual objects, and about the acquisition of RAMIS skill in dry-lab tasks and interaction with real objects. 
Motor control beyond reach: Challenges and insights from complex manual skills 
Functional interaction with objects - tool use - is essential in daily living and is regarded as the foundation for our evolutionary advantage. Surprisingly, however, how humans control objects or tools is still little understood. Manipulation of objects presents considerable additional control challenges beyond those in unconstrained reaching and pointing. This is readily highlighted in robotics where contact instability still presents a significant hurdle for robot manipulation and robot-human collaboration. Beyond interaction, the control of complex objects invariably requires more than a simplified end effector, two hands and the whole body, bringing the issue of redundancy front and center. This panel will focus on complex actions and interactions with complex objects that are still largely unchartered territory in motor neuroscience to date. Two speakers will feature novel methodological approaches on complex manual skills in humans; one speaker will present the challenges from the perspective of synthesis, i.e., the generation of dexterous robot manipulation; one speaker will showcase the unusually sophisticated tool behavior in New Caledonian crows that proved wrong the widely-held assumption that tool use is unique to humans. Together, the panel will raise questions on neural, mechanical, and genetic contributions necessary to achieve such intricate coordinate feats. Marta Russo will present recent work on whip manipulation. Using full-body motion capture, the study examined participants of different skill levels. She will show a three- pronged strategy to identify control principles in this prodigiously complex action: Analysis of the complex arm dynamics, analysis of the whip dynamics, and synthesis in simulation engines testing control elements or primitives. Antonella Maselli will present work on throwing of a ball to a target. She will show how spatiotemporal principal component decomposition of whole-body kinematics provides a compact way to identify individual strategies. Four main throwing styles are extracted that resemble different stages of throwing skill acquisition reported in motor development studies. Christian Rutz will introduce a non-primate model system for studying tool behaviors. New Caledonian crows exhibit striking dexterity when manufacturing tools from plant materials, when using these tools to extract insect prey from deadwood, and when storing tools in small holes. Remarkably, they achieve this dexterity with only simple ‘two-pronged grippers’, their bills. Aude Billard will provide a robotics perspective to tool manipulation. To understand and model this dexterity, her team examined cohorts of apprentices at watchmaking, a craft unique in the precision of control it requires. Her work unveils how two hands work in coordination to distribute control variables and achieve better precision than a single hand. Early work in transferring some of this ability to robotic hands will also be presented. 
The dynamics of manipulable objects are represented categorically as families or individuals 
Many theories about how object properties are encoded in memory have been proposed. These include theories concerned with the semantic, perceptual, and functional properties of objects. However, how the mechanical properties of objects are encoded remains largely unexplored. This is a critical question because the majority of tasks we perform involve object manipulation, where skilled performance requires the ability to predict object mechanical properties. Although motor control research has investigated how the brain learns about the dynamics of individual objects, it is not known how the dynamics of the myriad objects we interact with are organized in memory. Here we tested the hypothesis that the brain organizes objects categorically, into families, based on their appearance and mechanical properties. This hypothesis makes the counterintuitive prediction that people will fail to learn outlier objects that appear to be members of a family but whose dynamics deviate from that family. The alternative hypothesis, that the brain learns non-categorical associative maps linking visual features to mechanical parameters, predicts that outlier objects will be learned. Thus, while categorizing objects into families allows efficient encoding, it comes at the cost of representational accuracy for individual objects. For this work, we developed a 3D robotic interface coupled with stereoscopic VR that allowed us to accurately simulate objects of varying size, weight, and appearance, and we designed a novel lifting task that measured participants’ weight predictions on every trial. In the basic task, participants began by lifting a set of four objects sharing a common density (i.e., a putative family). Once these were learned, an outlier object with a different density was introduced. Remarkably, participants completely failed to learn the weight of this outlier object despite experiencing large, repeated movement errors; errors that, in the absence of a common-density family, quickly drove learning. We then manipulated this basic paradigm to further explore the nature of categorical encoding of objects. First, with extreme outliers, an individual memory for the outlier can be formed, effectively kicking the outlier out of the family. Second, even when an object is learned as an individual, subsequent learning of an object family reorganizes memory, pulling the individual into the family. Third, the boundary at which an outlier is kicked out of a family is not fixed, but depends on the history of sensorimotor experience. Fourth, although the categorization boundary varies across individuals, outlier objects are represented as either unique individuals or family members, such that they are either fully learned or not learned at all. These highly novel findings address, for the first time, how motor-relevant properties of multiple objects are represented in memory. 
Playing the piano with a robotic third thumb: Assessing constraints of human augmentation 
The development of human augmentation is driven by rapid technological advancement while little attention is devoted to how humans interact with the technology and learn to control it (Makin et Faisal 2017, Nat. Biomed. Eng). Contemporary robotics gives us mechatronic capabilities for augmenting human bodies. How our brains and bodies pose limits on such augmentation is an open question. Learning to control a supernumerary (additional) robotic limb is a complex process which involves learning to utilize one movement / set muscles activation to perform a new movement. Here we examine if individuals’ motor control capabilities can predict their ability to control a supernumerary robotic finger. Our robotic 3rd thumb was designed for playing the piano with the required force generation and stiffness in mind to play multiple keys in rapid succession, it is attached to the ulnar side of the palm and controlled by the foot (Cunningham et Faisal 2018, IEEE BioRob). We demonstrate that a pianist can learn to play the piano with 11 fingers within an hour. We then evaluate naïve and experienced piano players in their prior motor coordination and their capability in piano playing with the robotic augmentation. The participants performed 7 tasks to assess their foot and hand motor control. The tasks measured foot balance, foot up-down control, foot figure-of-eight tracking, piano key positioning, piano timing, piano key-press velocity, and hand movement complexity during a toy assembly task. Their accuracies were used as predictors of the scores for playing a short piano sequence with the supernumerary finger, which was measured in a second session (https:// bit.ly/3qnqmx3). Though learning to play with the supernumerary finger was slower than without, after around 30 minutes subjects have reached a learning plateau which was, on average, slightly lower than their score without the finger. Interestingly, foot dexterity (and not the piano playing related measures) was the best predictor of the performance with the supernumerary robotic finger. Additionally, there were no significant differences between pianists and non-pianists in playing with the robotic finger despite pianists having more task-relevant knowledge and experience. Our results suggest that the best predictor of the subjects’ performance with augmentation technology is the motor control capabilities of the control interface (in this case, the control of foot horizontal and vertical movements). Moreover, since knowledge of the task was not the determinant factor in the ability to control the augmented finger, it can be argued that specific motor capabilities are more relevant than experience in the task. A possible explanation for this is that controlling a supernumerary robotic device entails the creation of a new motor program, and each individual performance is closely related to their aptitude for learning new movement patterns related to the limb controlling the interface. 
Finger enslavement patterns after stroke are qualitatively different from coactivation patterns in the healthy hand 
Finger enslavement after stroke is often viewed as an exaggerated version of the coactivation pattern seen in the healthy hand, largely driven by mechanical coupling (Lang et al., 2004). However, it has been shown that finger coactivation patterns in the healthy hand can be quite variable (Ingram et al., 2008) and task dependent (Abolins et al. 2020). Here we directly compared coactivation patterns in the affected and unaffected hands and assessed to what extent the top-down vs. low-level constraints contribute to these patterns. Chronic stroke patients (N=13) and healthy participants (N=30) placed their hand in a customized device in a comfortable resting posture. The device can record small isometric forces from all 5 fingertips simultaneously in 3D. They controlled a dot in a virtual 3D space on a computer screen by exerting isometric forces with one finger (max=10N), when isolating a finger joint and keeping other fingers inactive. Movement of the dot along the virtual xyz axes reflected forces exerted by MCP ab/adduction, PIP flexion/extension, and MCP flexion/extension, respectively. From the recorded force trajectories, we calculated each finger’s Bias and Enslavement. Bias was the log force ratio of -/+ directions along xyz axes produced by the instructed finger. This captures the low-level force biases in an active finger. Enslavement was the force ratio between any given enslaved finger along the xyz axes and the force produced by the instructed finger. We then used linear mixed-effect (LME) models and representational similarity analysis (RSA) to analyze the enslavement patterns. We hypothesize that coactivation patterns in a healthy hand would be dependent on the instructed finger/target-directions, reflecting a top-down control strategy. In contrast, those in the paretic hand would be explained by the same low-level biases regardless the action of the instructed finger. If this is true, the large variance in the healthy pattern should be revealed by larger angular distances in RSA across different instructed finger/direction, whereas those for the paretic hand would be smaller. The LME results confirmed our hypothesis. Enslavement in the healthy hand could not be explained by Bias (p=.74) and was highly dependent on both instructed finger and target direction (p<2e-16), while paretic hand Bias was highly predictive of its Enslavement (p<2e-16), regardless of the instructed finger and target direction (p>0.09). The paretic hand finger enslavement was shewed towards the flexion directions. RAS analysis showed a significantly smaller angular distances among enslavement patterns across instructed fingers/directions in the paretic hands than those in the non-paretic hand (instructed finger: p<0.003; target direction: p<6.8e-09). We conclude that coactivation in the healthy hand is mainly driven by a top-down control strategy, whereas enslavement in the paretic hand reveals a low-level flexor bias due to injury in corticospinal tract 
Evaluating the impact of startle on speech production in individuals with post-stroke aphasia and apraxia. 
Application of startling acoustic stimuli during upper extremity movement in individuals with severe-to-moderate stroke increases muscle recruitment (faster, higher activity, and more frequent initiation) leading to increased reaching distances. These motor improvements have led to the exploration of startle as a therapeutic tool to enhance post-stroke arm movement. Startle-evoked arm movement has been explored extensively in the literature, and startle was recently shown to release pre-planned speech. Still, given that post-stroke speech disorders, such as aphasia (linguistic) and apraxia (motor), are highly cortical tasks, it seems less likely startle would be able to enhance speech post-stroke. The objective of this study was to determine if startle exposure can affect acoustic speech parameters during word repetition in individuals with post-stroke aphasia and apraxia. We compared acoustic speech metrics for startled vs. non-startled speech. Like upper extremity, we hypothesized that speech would be initiated faster, with higher activity (pitch and intensity), and with more frequent, appropriate speech production after startle exposure. We exposed 15 individuals with post-stroke aphasia and apraxia to startling, 105 dB white noise bursts during repetition of 6 words. We quantified speech onsets as the latency between cue and word onsets. Intensity and pitch averages for each word were extracted and normalized using Praat software. We defined errors as omissions, distortions, or additions, and calculated percent incidence of each startled vs. non- startled sound. Startled-speech onsets were 258 ± 350 ms faster compared to non-startled (p = 0.3). Onsets of startled speech were delayed in 60% of subjects by large inhales not seen during non-startled speech. Inhalations may result from hypermetric startle responses, which also interrupt startle-evoked arm movements. Startled speech was louder (Δ1.2 dB ± 0.6, p=0.001), but not higher in pitch (p=0.3). Contrary to our hypotheses, startle trials had errors 60% of the time vs. 35% in non-startle trials (p = 0.02). Still, preliminary data suggest startled words have 6% higher rate (p=0.09) of difficult sounds requiring sustained activity (e.g. “f”, “w”)-- sounds which were not achievable in non-startled speech. In conclusion, exposing individuals with post-stroke aphasia and apraxia to startle results in faster and louder speech. For startled speech, accuracy decreased but was accompanied by higher incidence of novel (to the subject) sounds that could not be produced without startle. This is analogous to results in upper extremity showing higher probability of muscle activity onset in severe subjects unable to voluntarily activate their arm muscles. The ability to make louder, sustained, and novel sounds implies startle may give subjects more lip, tongue, vocal fold, and airway control. Future work should determine if these changes can be harnessed to enhance voluntary post-stroke speech. 
Contextual inference underlies the learning of sensorimotor repertoires 
Humans spend a lifetime learning, storing and refining a repertoire of motor memories. For example, through experience, we become proficient at manipulating a large range of objects with distinct dynamical properties. This ability relies on motor adaptation driven by sensory cues, such as the visual appearance of objects, as well as proprioceptive feedback during interaction. However, it is unknown what principle underlies how our continuous stream of sensori-motor experience is segmented into separate memories and how we adapt and use this growing repertoire. Here we develop a principled theory of motor learning based on the key insight that memory creation, expression, and updating are all controlled by a single computation--contextual inference. In the COIN (COntextual INference) model, the environment consists of a (potentially) infinite number of discrete contexts that transition according to a Markov process. Each context has a state that evolves as a linear dynamical system independent of the other states. The current context leads to the emission of a sensory cue (sensory input that does not depend on action, such as the visual appearance of a scene) and state feedback (the sensory consequences of motor commands). Crucially, contexts are not labeled and hence a major challenge for the learner is to continually infer which context they are in based on the sequence of sensory cues and state feedback signals observed so far. As the COIN model uses principled Bayesian inference to estimate the current context, it fuses information from multiple sources: prior expectations about the current context (based on the history of contexts inferred so far) and the probability that the current state feedback and sensory cues could have been generated by each context. The result of contextual inference is a posterior distribution expressing the probability that each known context, or a yet- unknown novel context, is active. In turn, in each moment, this continuously evolving posterior controls how much existing memories associated with each known context should be expressed and updated, or whether it is time to create a new memory. Unlike dominant theories of single-context learning, our theory accounts for key features of motor learning that had no unified explanation: spontaneous recovery, savings, anterograde interference, how environmental consistency affects learning rates, the distinction between explicit and implicit learning and the ability of a working memory task to evoke the memory of a previous context. Critically, our model predicts novel phenomena--evoked recovery and context-dependent single-trial learning--which we confirm experimentally. These results suggest that contextual inference, rather than classical single-context mechanisms, is the key principle underlying how a diverse set of experiences is reflected in our motor behavior. 
Implicit visuomotor adaptation without movement 
To compute the sensory prediction errors that drive motor adaptation, the nervous system must compare the expected and observed consequences of movement. The expected consequences of movement are thought to be computed by a forward model of effector dynamics, which takes a motor command as input and predicts the sensory states that should result from that movement [1]. While motor planning signals help the motor system separately update competing internal models [2], it is unclear whether the forward model can learn using only a motor plan as input. That is, does motor adaptation require actual movements to be made, or is a command and an observed sensory event all that is needed? We propose that if motor planning provides sufficient input to the forward model, the resulting prediction can be combined with feedback to compute a sensory prediction error and support motor adaptation in the absence of movement. To test this, we trained participants on a visuomotor adaptation task in which they controlled a visually-displayed cursor using a computer mouse. We displayed visual cursor error feedback (a fixed 15 degree visuomotor rotation) on trials where participants executed reaches (Execution trials) and on trials where participants planned - but did not execute - reaches (Planning-Only trials). To ensure that we only measured implicit learning, participants were instructed to aim directly for the presented targets, regardless of cursor feedback [3]. On Planning-Only trials, the visual target appeared but was quickly followed by a “No-Go” cue, prompting participants to plan a reach to the target but not execute it. Immediately following the “No-Go” cue, an animation showed cursor error feedback, even though no movement was elicited. On Execution trials, the same target appeared, but the “No-Go” cue was omitted, prompting participants to actually execute a reach that was accompanied by cursor error feedback. Because Planning-Only and Execution trials were embedded within triplets of reaching trials with unperturbed feedback, implicit adaptation could be measured as the change in reach angle between the first and third trial of each triplet. In line with prior work, we observed robust trial-by-trial implicit adaptation opposite the direction of the rotated visual feedback on Execution trials. Crucially, we also observed robust implicit adaptation after Planning-Only trials. These data suggest that motor planning alone can provide a sufficient input to the adaptation system to generate sensory predictions, sensory prediction errors, and concomitant adaptive adjustments - all without the need for overt movement. Additionally, these data indicate that movements per se are not always necessary for implicit motor learning: salient sensory predictions and unexpected sensory feedback are sufficient. 
M1 GABA relates to functional connectivity changes and retention in visuomotor adaptation: A 7T MRS study 
Interacting with our ever-changing physical environment requires continual recalibration of the motor system. One mechanism for this is motor adaptation. Understanding how motor adaptation is implemented by the human brain, how different regions work in concert to adapt, and how this function relates to metabolic use of neurochemicals poses an important challenge in neuroscience. In humans, motor sequence learning is related to γ-aminobutyric acid (GABA) concentration in the primary motor cortex (M1). However, the role of M1 GABA in adaptation - where behaviour is thought to be acquired outside M1, but retained within M1 - is unclear. In this within-subject, crossover study, we quantified GABA and Glutamate from the hand region of the left human primary motor cortex (M1) using 7T-MR Spectroscopy while participants (n=15) performed a visuomotor task with or without an adaptation component (control condition vs. rotation condition). In the rotation condition, participants were required to adapt their centrifugal shooting movements to a rotation of the visual feedback which increased stepwise by 10 degrees after every block of 40 trials in order to drive adaptation throughout the duration of the scanning session. To probe retention participants performed a washout behavioural task after each MR session. We collected resting-state fMRI data immediately before and after the task. In the rotation condition, participants adapted to the increasing rotation, (LME of error in first and last epoch; effect of epoch χ2(1)=55.58 p<0.01). Participants retained the adaptive movement in the first block of the washout (one-sample t-test of washout error: t = -9.63 p<0.01). We first replicated changes in functional connectivity known to occur in response to adaptation: adaptation increased functional connectivity in a cerebellar network. Further, change in network strength correlated with adaptation (r=-0.65 p=0.01). We next tested our specific hypothesis regarding a link between M1 GABA, M1-Cerebellar connectivity and retention. We found that higher baseline M1 GABA relates to greater retention of adaptation (r =-0.62 p=0.02) but does not relate to adaptation-acquisition (r = 0.07 p =0.82). Moreover, M1-Cerebellar connectivity change is associated with retention (r=0.68, p=0.01), but not adaptation (r=0.05 p=0.87). Finally, M1 GABA relates to M1-Cerebellar connectivity change (r =-0.63 p=0.03). A mediation analysis revealed that M1- Cerebellar connectivity change mediates the relationship between M1 GABA and retention (confidence interval for mediation coefficient excludes zero: ab=-23.87; 95%-CI -62.29, -1.8). Our results showed that a) participants are able to adapt to a stepwise increasing rotation, b) this adaptation process increases connectivity in a cerebellar network and c) retention of the adapted state is associated with baseline M1 GABA. The relationship between M1 GABA and retention is mediated by M1-Cerebellar connectivity change. 
Brain and behavioral evidence for reweighting of vestibular inputs with long-duration spaceflight 
Microgravity results in altered vestibular signaling. Animals adapt to this, reflected in post-spaceflight declines in vestibularly-mediated behaviors such as balance and eye-head coordination, Readaptation to Earth’s 1G environment occurs during the weeks postflight. Here, we examine how a long-duration International Space Station mission influences the neural correlates of vestibular processing in humans. We used functional magnetic resonance imaging (fMRI) to measure brain activity in response to pneumatic cheekbone taps (i.e., a validated method of vestibular stimulation) versus rest in 15 astronauts before and after spaceflight. We also measured balance, mobility, and performance on a visual orientation task. Data were collected twice pre-flight and four time points post-flight (spanning out to six months post-flight). This allowed us to quantify vestibular and behavioral changes with spaceflight and to map the time course of readaptation to Earth’s gravity. As expected, vestibular stimulation at the pre-flight baseline sessions elicited activation of the parietal opercular area (i.e., vestibular cortex, OP2) and deactivation of somatosensory and visual cortices. Pre- to post-flight, we found widespread reductions in this somatosensory and visual cortical deactivation during vestibular stimulation, supporting sensory compensation and reweighting with spaceflight. These observed brain changes recovered towards baseline values by six months post-flight. Further, the observed pre- to post-flight changes in brain activity correlated with changes in standing balance; greater pre- to post-flight reductions in deactivation of visual cortices were associated with less post-flight balance decline. This suggests in-flight sensory reweighting; this reweighting then facilitates more adaptable post-flight standing balance when crewmembers are readjusting to normal vestibular inputs. Additionally, shorter flight durations correlated with greater pre- to post-flight reductions in cerebellar deactivation (similar to what we reported as the overall effect in the somatosensory and visual cortices). Although it seems counterintuitive that shorter missions would result in larger brain changes, we suggest that this reflects non-linear adaptation effects over time within the cerebellum. Together, these findings provide evidence for sensory reweighting and adaptive cortical neuroplasticity within the vestibular system with exposure to a novel microgravity environment. These results have implications for better understanding compensation and adaptation to vestibular functional disruption. 
Effect of varying levels of sensory prediction error on the internal model prediction and suppression of reafferent signals in the deep cerebellar nuclei 
Repetitions of a motor task are characterized by natural variability despite successful execution. Optimal feedback control theorizes that the brain does not enforce the precise details of the movement across the time course, rather, it uses feedback to optimize achieving the movement goal. This leads to the open question, how are small errors in sensory prediction (SPE) encoded during movement in the presence of natural trial-to-trial variability? The cerebellum is involved in error-based learning, and the deep cerebellar nuclei (DCN) constitute a major output of the vestibular cerebellum for rapid modulation of postural responses. Notably, while these pathways are essential for responding to externally-applied perturbation, they would be counterproductive during self-generated movements. Previous studies by our group have shown that DCN activity reflects the output of a forward internal model that calculates and suppresses self-generated (reafferent) sensory signals in order to distinguish these from externally- applied (exafferent) signals. Specifically, DCN neurons demonstrate a marked suppression in sensitivity during active head movements, meanwhile, large errors (~50% reduction in velocity) are encoded as if the movement was externally-applied. The aim of this study is to determine how varying magnitudes of SPE influence DCN sensitivity. One possibility is that SPE will not influence DCN sensitivity until SPE reaches a magnitude that exceeds the range of natural movement variability. We recorded the activity of DCN neurons (rostral fastigial) in one rhesus monkey during passive and active movements of the whole body, head on body, and body under head. Neurons were identified as primarily bimodal in that they encoded both passive vestibular (whole body) and neck proprioceptive (body under head) stimulation in opposite directions, and demonstrated reafferent suppression during active head on body movement. Next, we introduced different levels of SPE by applying assistive or resistive velocity dependent loads unexpectedly during a fraction of active head on body movement trials. The smallest levels of error changed head velocity within the band of natural variability, while the largest levels approximately doubled (assistive) or halved (resistive) head velocity. Some neurons showed a gradual reduction in reafferent suppression (i.e., increase in neural sensitivity) when loads increased in both the assistive and resistive directions. The neurons that demonstrated this tended to have higher baseline sensitivities to passive vestibular relative to neck proprioceptive signals. These findings suggest that there is a gradual shift in encoding from reafferent to exafferent as the error in sensory prediction increases. Taken together, these data provide insight into how the cerebellum performs computations on small differences between the internal model’s prediction of head movement and the actual head movement. 
Manipulating a whip - learning to control dynamically complex objects 
One of the paradoxes of human motor neuroscience is that human sensory-motor abilities vastly out-perform modern robot technology, despite the slow neuromuscular system. A possible resolution of this paradox is that humans rely heavily on prediction based on some form of internal model. Neural and behavioral evidence supports the existence of such models, yet the exact nature of the model itself still remains to be clarified. We hypothesize that the internal model used for motor control is based on (at least) three distinct classes of motor primitives: submovements and oscillations, which provide a basis for unconstrained movements, and mechanical impedance, which facilitates physical interaction. Encoding movements with combinations of these motor primitives may be an essential simplification required to enable dexterous manipulation of complex objects. To test this hypothesis, we examined how humans learn to manipulate one of the most exotic and complex tools which they can handle: a whip. In simulation, we tested whether a distant target could be reached with a whip by using a controller composed of motor primitives. The motor learning process to reach a distant target with a whip was framed as an optimization problem, where the goal was to find an optimal set of parameters that could minimize the distance between the tip of the whip and the target. Multiple target locations were tested, with the upper-limb and whip modelled as a chain of 54 DOF, yielding a 108-dimensional state-space representation. We discovered that, regardless of the target location, this approach was able to manage this daunting complexity, and optimization succeeded to identify the optimal movement parameters that could reach a target with a whip. A detailed model of the whip dynamics was not needed for this approach, which thereby dramatically simplified the learning process. This may be a key simplification which humans use to learn complex motor skills, since only a small set of parameters may need to be determined and retained without the need to internalize the detailed dynamic properties of the object being manipulated. Experimental studies also observed that humans appear to employ a small number of primitive actions to hit a target with a whip. However, there were differences between simulation and experiment: in simulation, the task was accomplished with a single submovement planned in joint-space coordinates; experimental studies showed two submovements in end-effector coordinates. Nevertheless, these investigations support our hypothesis that an internal representation encoded in terms of primitive actions may be a key strategy underlying successful mastery of dynamically complex objects. 
Back to reality: Differences in learning strategy in a simplified virtual and a real throwing task 
Virtual environments have been widely utilized in motor neuroscience and rehabilitation as they afford tight control of sensorimotor conditions and readily afford visual and haptic manipulations. However, typically studies have only examined performance in the virtual testbeds, without asking how performance in the virtual environment compares to behavior in the real world. To test whether performance in the virtual environment is a valid representation of corresponding behavioral features in the real world, this study compared throwing movements in a virtual set-up with throwing in a real set-up; importantly, the task parameters were precisely matched. Similar to many studies on reaching, the movements in the virtual set-up were constrained to single-joint arm movements in the horizontal plane, in contrast to the full unconstrained arm and hand movements in the real performance. Nevertheless, throwing accuracy and precision was significantly better in the real task; it took three practice days until subjects in the virtual task reached similar levels of success rate and error. To gain more insight into the structure of the learning process, movement variability was decomposed into deterministic and stochastic contributions. Applying the Tolerance-Noise-Covariation decomposition method revealed distinct stages of learning: Tolerance was optimized first in both environments, but it was higher in the virtual environment, suggesting that more familiarization and exploration was needed in the virtual task. Covariation and Noise showed contributions only late in practice, and only in the real task. The latter two components indicated that subjects reached the stage of fine-tuning of deterministic and stochastic aspects of variability in the real and not in the virtual task. Additionally, due to fewer constraints in the real task, subjects could modify the geometry of the solution manifold, by shifting the release position, and thereby simplify the task. These results demonstrated that while the tasks were precisely matched, the virtual environment required more time to be successful, even though the arm movements were significantly simpler. These findings highlight that restriction of the arm movements to fewer degrees of freedom is not necessarily simplifying the task for the subject. These findings also resonate with the reported problems in transfer of therapeutic benefits from virtual to real environments and alert that the use of virtual environments in research and rehabilitation needs more caution. 
The hot and cold streaks in reinforcement learning 
There is a widespread belief in sports that success breeds success and failure breeds failure. This--the “myth of the hot and cold streaks”--has been debated for decades. While studies have shown that the hot streak is a fallacy of the human mind (Gilovich et al., 1985; Shaw et al., 1992), some suggested that it is inappropriate to search for streaks in rich contexts where the effect can be masked by other effects (Kaplan, 1990; Koehler et al., 2003). Here, we hypothesized that the streaks are caused by the reinforcement learning mechanism, in which success decreases movement variability and failure increases it (Pekny et al., 2015). The current study tested the existence of streaks using an arm-reaching paradigm. Thirty-three healthy young adults participated in the experiment. On each trial, participants attempted to reach and pass the target shown 10 cm in front of the start position without visual feedback of hand location. Binary feedback (success/failure) was given based on whether the hand path overlapped the target. The target size was adjusted individually using the baseline movement variability and kept constant for the whole main experiment. The group results showed that the occurrence probability of two successive failures was 1.13 ± 0.06 times higher than the square of the failure probability for the whole experiment, demonstrating that failure streaks occurred above the chance level. Two successive successes also occurred above the chance level. Runs test on individual performances found that 27 participants (82%) had fewer runs (more streaks) than expected, of which eight participants had significantly fewer runs (p < 0.05). A model in which motor variability consists of constant noise and exploratory action, regulated by recent reward history that increases variability with poor performance (Dhawale et al., 2019), successfully accounted for the appearance of streaks. These results illustrated that hot and cold streaks emerge from the process of motor exploration, which regulates movement variability. Concurrent pupillometry showed that pupil diameter at the time before the movement onset was not different between success and failure trials, suggesting that a reduction in task engagement reflected by larger pupil diameter was not a confounding factor for performance. Furthermore, both successive successes and failures did not occur above the chance level in the follow-up experiment (N = 11) using seven reaching targets shown in the range of ±90° from the start position. The results suggested that the emergence of streaks is action- dependent. In other words, when we missed a target, it would be less likely to fail on the next trial if we aim for different targets. Further research is needed to understand the contextual factors that induce hot streaks and that suppress cold streaks. 
Train one, gain two: Tool use and syntactic skills improve each other via shared neural patterns in the basal ganglia 
Learning transfer from trained to untrained functions have been reported within the motor and other cognitive domains, provided that the involved functions share neuro-cognitive resources. Studies have shown that tool use and syntactic processing of language display neural similarities in the basal ganglia (BG) and the left inferior frontal gyrus. These lines of research have yet grown apart, and the anatomical overlap between tool use and syntax remains anecdotal. Here, we questioned the extent and functional relevance of this potential overlap in healthy right-handed participants (20-40yo). Then, we behaviorally assessed cross-domain transfer 1) from tool-use learning to syntactic processing and 2) from syntax training to tool-use ability. Using fMRI (n=20), we examined object and subject relative clauses comprehension and, as a control, working memory (WM). Additionally, participants performed a motor task using a tool or the free hand. We examined the anatomical overlap between tool use and syntax activations, together with its functional relevance, through conjunction and representational similarity analyses (RSA). In a first behavioral experiment (n=78), we tested cross-domain benefits of motor training onto syntax. Motor training consisted of inserting pegs with either the tool or the free hand. In a further experiment (n=39), we controlled for motor difficulty as an unspecific factor of transfer, by comparing two groups trained as previously (tool or free hand) with a third group undergoing a hand training mimicking tool-use constraints. Finally, we tested the transfer in the opposite direction (n=48), by assessing tool-use abilities after training with complex syntactic structures (i.e. object relatives), or as a control, with simpler ones (i.e. subject relatives). Tool-use planning and syntax networks both involved the left fronto-parietal cortex and BG. Activity overlapped in the left caudate and the bilateral pallidum, where RSA showed stronger patterns similarity between object relatives and tool use. No overlap was found with hand planning nor between tool-use planning and WM. Behavioral experiments showed that performance for most complex syntactic structures significantly improved only after tool use, as compared to both free and constrained hand training. Furthermore, we showed these benefits were bi-directional: training complex syntax improved tool-use abilities, whereas training simpler syntax did not. Overall, our findings highlight the functional overlap between tool-use planning and complex syntactic processing within the BG. Behaviorally, this is reflected by bi-directional cross-domain transfer, where tool use benefits to syntax and vice-versa. This network might subserve similar functions for tool use and syntactic comprehension, such as handling complex hierarchical sequences, either in the motor or linguistic domain. Accordingly, we posit the existence of a supramodal syntactic function supported by the BG. 
Sensorimotor processing for forelimb movement 
A critical challenge faced by the mammalian motor system is the coordination of dozens of muscles in the forelimbs to interact with the world. The precision of forelimb behaviors implies feedback pathways dedicated to the ongoing refinement of motor output. The dorsal column nuclei (DCN), located in the brainstem, represent the major conduit of somatosensory information from the periphery to supraspinal targets. Of the DCN, the cuneate nuclei are tasked with receiving and processing forelimb cutaneous and proprioceptive signals and conveying the resulting sensory information to the sensorimotor cortex via cuneolemniscal projections to the thalamus (amongst other subcortical targets). The cuneate nuclei also receive a diversity of other inputs, including from the cerebral cortex, suggesting top-down modulation of sensory signals. Defining how the nervous system orchestrates behavior demands an understanding of how feedback represents and refines movements, and the cuneate nuclei provide a fundamental and tractable location for exploring the anatomical and functional logic of feedback control. By describing recent progress in our understanding of the cuneate in primates and mice, this panel aims to integrate diverse approaches into a more complete description of sensorimotor control. Four speakers were selected for their ongoing work exploring how cuneate neurons process different types of sensory information, how these signals are modulated by descending pathways during behavior, and how cuneate circuits respond to injury and are rewired to restore function. Kazuhiko Seki will present anatomical, electrophysiological, and behavioral findings that delineate bottom-up and top-down inputs to the cuneate nucleus of nonhuman primates, providing insight into how cutaneous and proprioceptive feedback might be modulated during movement. Sliman Bensmaia will describe how tactile responses in primate cuneate imply the convergence and processing of signals from multiple cutaneous submodalities, which are then subject to top-down influences. Eiman Azim, will discuss work in mice identifying local and descending circuits that modify cutaneous feedback in the cuneate and participate in the execution of tactile-guided behaviors. Corinna Darian-Smith will describe how cuneate circuits respond to injury of sensory pathways, and how compensatory rewiring can aid functional recovery. Chris Versteeg will then lead a panel discussion focused on key themes, including: a) How movement affects the transmission of sensory feedback and the implications of this modulation for refining motor output; b) How somatosensory processing in the cuneate might relate to other sensory modalities; c) The degree to which different aspects of feedback circuit organization are conserved across mammalian species, and what this might teach us about human sensorimotor control. 
Beyond somatotopy: functionally relevant information content distributed across S1 and M1 Homunculus 
Contrary to its motor counterpart, the primary somatosensory cortex (hereafter S1) is considered to be highly topographically organised, with relatively high levels of selectivity within each representation along the homunculus. While this organising principle appears to be a dominant feature of S1, it may eclipse orthogonal organising principles. Recent neuroimaging methodology (MVPA) allows us to identify representational features beyond selectivity, e.g. information content, providing new opportunities to characterise the homunculus. Using complementary approaches, a recent study in tetraplegic patients revealed the presence of latent activity, evoked by movements from the entire body in the motor hand region (Willett et al, 2020). Knowing that the M1 and S1 hand area share similar representational features (Ejaz et al, 2015), we asked whether body-part information content can be identified in S1 beyond the primary area of a given body part. We analysed fMRI activity patterns evoked when healthy participants performed i) individual fingers movements, ii) movements of specific face parts, or iii) two different actions (squeeze or push an object) with each of 4 body-parts (lips, hand, arm, feet). To index information content, we used Representation Similarity Analysis to identify dissimilarities between actions and body-parts. Individual regions of interest of S1 showing high univariate selectivity to face, hand and foot movements (hereafter primary areas) were independently defined. First, comparing dissimilarities between body- parts, we identified significant dissimilarity between non-primary body-parts (e.g., between the hand and the mouth in the foot area) throughout the homunculus. We also observed significant dissimilarity between sub-body parts (e.g., individual fingers) in non-primary areas spatially remote (e.g., face parts in the foot area). Together, these results show that body-part information content is widely distributed across the homunculus, allowing for instance the foot area to tease apart hand and mouth movements, but also distinguish between different facial movements. Finally, we compared dissimilarities between the squeeze and push movements done with each body-part. In line with the topographic organisation, the primary body-part of each area (e.g., the feet in the foot area) displayed significantly higher dissimilarity between the two actions than non-primary body-parts. However, significant dissimilarity between the two actions was observed also remotely (e.g., between squeeze and push movements with the hand in the feet area). Altogether, these results show that body-part and action related information content is more distributed across S1 homunculus than previously thought. While this does not revoke the general topographic organising principle of S1, it reveals a new level of richness regarding its information content that could be harnessed for rehabilitation, augmentation or brain-machine interfaces. 
Firing rate changes in motor cortex during corrective reaching show repeated patterns of condition- independent activity coupled with increased neural variability 
While most studies of neurons in primary motor cortex during reaching have focused on their tuning to movement parameters like muscle activity or reach direction, it is known that neurons’ firings rates change relative to baseline for most movements in addition to being tuned to the particular direction of movement. Additionally, rather than a rise and fall in activity time-locked for all neurons, a more complex neural trajectory in the neural space with an ordered progression of some neurons leading and others lagging has been observed. These descriptions of condition-independent activity and neural trajectories create a challenge for describing the neural encoding of movement beyond single movements. It is unclear if and how these neural dynamics in motor cortex influence the brain’s ability to integrate new sensory information and timing of corrective movements. To explore these questions, we had monkeys (Macaca mulatta) perform precision center-out reaching to small targets. In this precision task, the animals often needed to make additional corrective movements after an initial reach if they did not land precisely within the small target. For the trials with subsequent movements after the initial reach, we found the movements could be divided into submovements by identifying when multiple speed peaks occurred during a trial. These submovements were observed to have similar bell-shaped velocity profiles as a function of time whether they were during the initial reach or subsequent corrective movements. The neural recordings showed a consistent, cyclic neural trajectory in certain dimensions of the neural space that occurred during the initial reach and was repeated when the animal needed to make additional corrective submovements. The timing of peak movement speeds was phase-locked with these cyclic neural trajectories and were a better predictor of when speed peaks occurred than simply the instantaneous firing rate across the population. The average change in firing rate for many neurons was nearly as large for the repeated cycles during the smaller amplitude movements as large ones. Additionally, when examining the neural population space, the total firing rate variance across submovements was actually larger for corrective submovements than initial submovements and the dimensionality of the neural space was higher for corrective submovements than initial submovements. Suggesting that a greater variety of neural patterns were observed for the corrective submovements and that global change in firing rate is not simply representing movement speed. Some of the neural activity in primary motor cortex thus appears to represent a truly condition- independent increase of neural activity that subdivides the execution of each submovement. Additionally, a variety of neural firing patterns appear to give the brain flexibility to encode the various amplitudes of initial and any subsequent submovements that are required for precise reaching. 
Cortical responses during overt force production and corresponding covert motor imagery 
Brain-computer interfaces often rely on a subject producing motor imagery without causing actual overt limb movement. In situations where the overt movement is physiologically possible--as with human participants who retain residual limb function or intact nonhuman primates--it is unclear how specific features of covert (non- movement-causing) cortical activity differ from those of actual overt control. Motor BCIs can be calibrated using overt limb movement and then operated without it, indicating a significant degree of overlap between the two. However, BCI use alone cannot entirely address the difference between overt and covert action, as it imposes neuron-to-output mappings that do not exist during natural motor imagery or action rehearsal. Here, we aim to characterize how specific components of cortical activity differ between overt force production and equivalent covert imagery. We recorded intracortical neural responses from both the hand and arm areas of primary motor cortex as a human participant with tetraplegia (who retains residual upper arm function) performed an isometric wrist extension task, switching between overt force production and covert motor imagery of the same action. The participant first alternated between two levels of isometric wrist extension force (10% and 60% MVC), and then repeated the experiment using covert motor imagery; he imagined performing the same actions without producing external forces. We found that when analyzed independently, the overt and covert conditions contained remarkably similar population-wide responses. In both cases, the cortical activity could be decomposed into three basic features: a transient response at the onset of force (real or imagined), a sustained response throughout force production, and a transient response at the offset of force. However, we found varying degrees of similarity between the specific neural dimensions (population-wide correlations) that contributed to these three temporally distinct features. The dimensions containing a sustained response throughout force production were roughly aligned across the two conditions, indicating that neurons exhibiting tonic responses throughout force production tended to be similarly active for both actual and imagined behavior. Conversely, the dimensions containing transient responses at the onset and offset of force were nearly orthogonal between conditions. Thus, while both imagined and actual force production contained transient responses at force onset and offset, those responses were distributed across two unique ensembles of neurons. Together, these findings suggest that cortex might control the presence/absence of motor output (action vs. imagery) by altering specific neural dimensions at the onset of an otherwise identical dynamic process. 
Probing motor adaptation in an artificial neural network model 
Animals, including humans, have a remarkable ability to adapt their movements to changing external conditions. Yet, disentangling the underlying neural mechanisms remains challenging. Dorsal premotor (PMd) and primary motor (M1) cortex play essential roles in movement planning and execution. Accordingly, adaptation is reflected in the neural activity changes within these areas. These changes can be caused by 1) local synaptic plasticity or 2) altered input. As experimentally measuring synaptic connectivity or input currents remains challenging, our current understanding builds on interpreting extracellular recordings. Recent studies have shown that the patterns of coordinated neural activity, or neural covariance, remain stable both in M1 and PMd during motor adaptation. This has been associated with stable underlying connectivity. However, we lack ground truth data to verify this presumed association; nor do we have estimates of the magnitude of the connectivity changes necessary to counteract the perturbations applied experimentally. To investigate whether motor adaptation is mediated by either changes in recurrent connectivity or external inputs, we implemented a modular recurrent neural network model simulating PMd and M1. The model was trained to produce hand trajectories performed by monkeys during a center-out-reach task. Next, we applied a motor perturbation and retrained the model either using recurrent weight changes or altered inputs. This allowed us to compare the resulting changes in unit activity and covariance to those occurring in neural recordings from PMd and M1 during the same adaptation tasks. Intriguingly, adaptation through recurrent weight changes produced surprisingly small changes in unit activity with largely preserved covariance, comparable to experimental data. The underlying weight changes were small and highly correlated, which provided high robustness against random weight fluctuations. Comparing adaptation through weight changes and altered inputs showed that both had a similar effect on unit activity and preserved covariance to a comparable degree. We concluded that the behavioral adaptation needed in the tested tasks might be too small. Therefore, we also probed the model under larger visuomotor rotations and a visuomotor reassociation task. This led to larger changes in neural activity and covariance. Comparing these predictions to experimental recordings, especially for the reassociation task, might help to disentangle the two alternative learning hypotheses in the future. In summary, our model provides evidence that learning through input changes or local synaptic plasticity can have similar effects on neural covariance, making it difficult to differentiate between the two based on neural recordings alone. We propose that more challenging behavioral tasks, as well as more sophisticated analysis of inter-region communication, may be needed to clearly disentangle the two hypotheses. 
Corollary discharge and oculomotor proprioception: Two strategies for spatially accurate movement 
In order to link perception and action the brain must have a spatially accurate representation of the visual world, so it can generate actions appropriate to the objects it perceives. The only way visual information enters the eye is through the retina, which moves constantly between brief fixations. The retinal location of targets for action is not useful for calculating movements to acquire those targets. Two strategies have been postulated to calculate the accurate location of movement targets: Helmholtz suggested that the brain knows the command to move the eye, and therefore can use that motor command to update the sensory representation. This feedback from the motor system to the sensory system is now known as corollary discharge. Sherrington suggested that the brain can calculate accurate target location if it knows the position of the eye in the world, and the first step in this process is to know the position of the eye in the orbit. He postulated that this signal arose from oculomotor proprioceptors. The lateral intraparietal area (LIP) is a brain region important in choosing targets for saccadic eye movements, and solves the spatial accuracy problem using both Helmholtz’s and Sherrington’s strategies: a rapid, relatively accurate corollary discharge mechanism, and a slower, but more accurate proprioceptive mechanism, which is dependent upon the sensory representation of eye position in Area 3a of the primary somatosensory cortex. 
